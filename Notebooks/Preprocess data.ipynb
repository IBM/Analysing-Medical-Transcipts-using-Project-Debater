{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess Medical Transcriptions Dataset for Analysis with IBM Project Debater\n",
    "\n",
    "### Introduction\n",
    "This dataset contains sample medical transcriptions for various medical specialties. It was downloaded from [Kaggle](https://www.kaggle.com/tboyle10/medicaltranscriptions) on 03/09/2021. Its output is the dataset that's used in the notebook `Key_Point_Analysis`, which uses Project Debater to extract key points from sentences in medical transcriptions.\n",
    "\n",
    "For more information about IBM Project Debater, please refer to the Readme file of this repo and the above-mentioned notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read dataframe\n",
    "df = pd.read_csv('./mtsamples.csv').drop(columns=['Unnamed: 0'])\n",
    "print('Shape:',df.shape)\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Duplicates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Sample names\n",
    "print('Unique sample names:', df['sample_name'].nunique()) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are fewer sample names than observations. Some may relate to the same patient? Need to check for duplicates."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mark duplicates\n",
    "df = df.sort_values(by = ['transcription', 'description'])\n",
    "df['dup'] = df.duplicated(subset = ['transcription', 'description'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# View a slice of the dataframe\n",
    "df[100:120].head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are quite a few duplicates. It seems that the same case was classified in several categories, probably at different times during the treatment. Notice that one of the observations for a patient are sometimes put in generic categories such as \"Discharge Summary\" or \"Counsult - History and Phy.\" (but not always). \"Surgery\" is also so prevalent that it is almost not informative. To get rid of these categories, I am going to replace them by the more informative pair, if it exists. Then, I am going to drop duplicates with respect to the subset `description` and `transcription` and keep the first observation for each. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Replace uninformative medical specialties\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "df['medical_specialty_new'] = df['medical_specialty']\n",
    "generic_cat = [' Surgery', ' Consult - History and Phy.', ' Discharge Summary', ' SOAP / Chart / Progress Notes', ' Office Notes', ' Letters']\n",
    "for i in range(1, len(df)-1):\n",
    "    if (df['transcription'][i] == df['transcription'][i-1])&(df['description'][i] == df['description'][i-1]):\n",
    "        if (df['medical_specialty_new'][i] not in generic_cat) & (df['medical_specialty_new'][i-1] in generic_cat):\n",
    "            df['medical_specialty_new'][i-1] = df['medical_specialty_new'][i]\n",
    "\n",
    "df.head(10)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop duplicates\n",
    "df_nd = df.drop_duplicates(subset = ['description', 'transcription'], keep = 'first').drop(columns='dup')\n",
    "df_nd.reset_index(inplace = True, drop = True)\n",
    "print('Shape new df:', df_nd.shape)\n",
    "df_nd.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop observations with no transcription\n",
    "df_nd.dropna(inplace=True)\n",
    "\n",
    "# View data\n",
    "df_nd.tail(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Value counts of original medical specialty\n",
    "df_nd['medical_specialty'].value_counts(normalize=True).head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Value counts of modified specialty\n",
    "df['medical_specialty_new'].value_counts(normalize=True).head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems there's still lot of surgeries left, but it looks better."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate random dates and locations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from random import choices, seed\n",
    "seed(10)\n",
    "\n",
    "## DATES\n",
    "df_nd['year'] = choices([2010, 2013, 2016], k = len(df_nd)) \n",
    "\n",
    "## LOCATIONS\n",
    "boroughs = gpd.read_file(\"https://skgrange.github.io/www/data/london_boroughs.json\")\n",
    "df_nd['borough'] = choices(list(set(boroughs.name)), k = len(df_nd))\n",
    "\n",
    "df_nd.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Frequency of random years')\n",
    "df_nd['year'].value_counts(normalize=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Frequency of random locations')\n",
    "df_nd['borough'].value_counts(normalize=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export clean dataset to CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the whole modified dataframe\n",
    "df_nd.to_csv('./mtsamples_clean.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split description column in sentences and save for analysis\n",
    "df_nd_select = df_nd[['description', 'medical_specialty_new', 'year', 'borough']].reset_index().values.tolist() # Add month if required by analysis\n",
    "\n",
    "sentence_list = []\n",
    "for line in df_nd_select:\n",
    "    for sent in line[1].split('. '):\n",
    "        if len(sent) >= 4: # drop weird white-space-only lines\n",
    "            sentence_list.append([line[0], line[2], sent, line[3], line[4]]) # Add line[4] for month if required by analysis\n",
    "\n",
    "sentences = pd.DataFrame(data = sentence_list, columns=['id_description','medical_specialty_new','text', 'year', 'borough']) # Add month if required by analysis\n",
    "\n",
    "sentences.to_csv('./mtsamples_descriptions_clean.csv', index_label = 'id')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}